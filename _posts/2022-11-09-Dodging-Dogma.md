I've had an outline for my next piece, "Will Free Societies Cannibalize," open on my laptop for the past 6 months. It's complete-ish, but I could never make sense of my own conclusions. They brought more questions than answers. Going down the rabbithole I got lost, demoralized, and demotivated to continue on this pursuit. I'd like to give my sincerest thanks to those who provided words of encouragement in the lull.

My vision for this site was, and still is, to provide piecemeal chunks of perspective which ultimately fit together in a comprehensive ideology. This naturally poses challenges when disparate concepts bleed together, but, "Will Free Societies Collapse," soaked right down to, and muddied, my roots. What started as an essay on intra-polity considerations melded into inter-polity dynamics, and before long I was stuck in a rut of moral confusion evaluating different ways that intelligence may get through Earth's [Great Filter](https://youtu.be/UjtOGPJ0URM). And does any of it even matter, if all things may come to an end [eventually](https://en.wikipedia.org/wiki/Heat_death_of_the_universe#:~:text=The%20heat%20death%20of%20the,sustain%20processes%20that%20increase%20entropy.)?

My confusion was mixed further as I learned of family, friends, and acquaintances who don't share my Humanist view. Turns out I'd greatly overestimated the portion of us who care whether it's humanity or some other derivative intelligence which spreads the galaxy. Originally, it felt like a gut punch to hear of such apathy, and even disdain, for the human experience and consciousness. Over time this blow has bruised into a painful soft spot which I still don't have a clear rebuttle for. I haven't found a universally compelling defense of our species. This discomfort has, however, forced me to reflect and refine my beliefs.

For one, I now see that my existential concern for specifically Homo Sapiens was dogmatic and lacked nuance. If I were a Neanderthal would I have the same absolutist view regarding Neanderthal consciousness? Hopefully not.[^1] I hope I'd have the capacity to appreciate the modern human mind from the vantage of a neighboring branch on our family tree. Extending this thought experiment to today, what future derivations of humanity may we value similarly to our own? Surely there must be some.

One set of criteria I'm considering for this assessment could be summed up as the "warmness" or "coldness" of a mind. I'll get into this classification more in a future post, but I see it as having some relation to the degree in which a mind is socially oriented. A mind molded with strong social incentives, such as tribal survival, would probably[^2] be very "warm" in this sense; likely with a high emotional intelligence and very empathetic - skillful in imagining and understanding others' experiences. On the flip side, I imagine that the first AGIs to be birthed will be very "cold", as they'll likely be trained in isolated environments with relatively simple feedback mechanisms. In fact, they may be so "cold" that we consider them unconscious for that reason alone. The "warmness" or "coldness" of a mind plays a significant role in how I value it, and whether or not I'm existentially alright with it carrying on the torch of consciousness.

Take for instance what I consider to be the next most-likely derivation of humanity - humans with BMI implants. How might we be "warmer" or "colder" with an implant? Would attaching Google Search to your brain make you more factual and less intuitive? More or less self-centered? With greater memory (literally, RAM and Disk), might we have more intimate moments with close ones? Sharing past experiences in higher fidelity? I don't think it's universally true that BMIs are a bad idea, but I think they very very very likely will have some nasty side effects which slide us in the "cold" direction. More to come on this topic, in particular.

Finally, I have to put some limit on the timescales and scope I'm considering. We can only see so far ahead, and there's no signal to be wringed out by stretching existential worries to no end. Gamma-ray Bursts, Black Holes, and other celstial nightmares may pose some risk, but Humanity would be in great shape if they were actually our biggest threat. I'll center my focus on the technological singularity we are racing toward, and the potential it has to push us toward a singularity of consciousness. Being on an exponential, the most critical trends are taking place now and have never bore greater signs to be witnessed. May a rich flame of creation burn on and illuminate the cosmos.

Updating the [About](https://powaqqatsi.github.io/thoughts/about/) to reflect these changes in perspective...

[^1]: Note that this doesn't mean I would've accepted the Homo Sapien incursion into my homeland of Western Europe 200k years ago, and turned the other cheek as my family lost our traditional hunting lands. But, if my proto-human brain had the capacity to reason over timescales of millennia, and could see outside of itself, I'd hope to at least be unconcerned with the light of consciousness.
[^2]: Ants would be a good counter-example of this, right? Or are they in fact empathetic with high EQ? Need to work on this "warm" definition. And I wonder what came first, the hive mind or the worker drone? They did, afterall, have hundreds of millions of years to wirehead one another. Can't resist those Pheromones.
